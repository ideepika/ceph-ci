>=14.2.2
--------

* Nautilus-based librbd clients can now open images on Jewel clusters.

* The RGW "num_rados_handles" has been removed.
  If you were using a value of "num_rados_handles" greater than 1
  multiply your current "objecter_inflight_ops" and
  "objecter_inflight_op_bytes" paramaeters by the old
  "num_rados_handles" to get the same throttle behavior.

14.2.2
------

* The no{up,down,in,out} related commands has been revamped.
  There are now 2 ways to set the no{up,down,in,out} flags:
  the old 'ceph osd [un]set <flag>' command, which sets cluster-wide flags;
  and the new 'ceph osd [un]set-group <flags> <who>' command,
  which sets flags in batch at the granularity of any crush node,
  or device class.

* RGW: radosgw-admin introduces two subcommands that allow the
  managing of expire-stale objects that might be left behind after a
  bucket reshard in earlier versions of RGW. One subcommand lists such
  objects and the other deletes them. Read the troubleshooting section
  of the dynamic resharding docs for details.

* The telemetry module now has a 'device' channel, enabled by default, that
  will report anonymized hard disk and SSD health metrics to telemetry.ceph.com
  in order to build and improve device failure prediction algorithms.  Because
  the content of telemetry reports has changed, you will need to either re-opt-in
  with::

    ceph telemetry on

  You can view exactly what information will be reported first with::

    ceph telemetry show
    ceph telemetry show device   # specifically show the device channel

  If you are not comfortable sharing device metrics, you can disable that
  channel first before re-opting-in:

    ceph config set mgr mgr/telemetry/channel_crash false
    ceph telemetry on
